== T5 Platform HA Test Suite ==

* Setting
Documentation    T5 Controller Platform Test Suite
Suite Setup      T5 base suite setup
Suite Teardown   T5 base suite teardown
Test Setup       base test setup
Test Teardown    base test teardown
Force Tags       T5Platform  HA
Library          keywords/BsnCommon.py
Library		 	 keywords_dev/don/T5Platform.py
Library		 	 keywords_dev/don/T5Utilities.py
Library          keywords/Mininet.py
Library	    	 keywords/Host.py
Library          keywords/T5.py
Library	         keywords/T5Fabric.py
Resource	 	 keywords_dev/don/t5_platform_sanity_resource.txt

* Variables
${bm0_ip}  10.0.0.1
${bm1_ip}  10.0.0.2
${bm2_ip}  10.0.0.3
${bm3_ip}  10.0.0.4
${bm4_ip}  10.0.0.5
${bm5_ip}  10.0.0.6
${bm0_mac}  00:00:00:00:00:01
${bm1_mac}  00:00:00:00:00:02
${bm2_mac}  00:00:00:00:00:03
${bm3_mac}  00:00:00:00:00:04
${bm4_mac}  00:00:00:00:00:05
${bm5_mac}  00:00:00:00:00:06
${bm0_intf0}  leaf0a-eth8
${bm0_intf1}  leaf0b-eth8
${bm1_intf0}  leaf0a-eth9
${bm1_intf1}  leaf0b-eth9
${bm2_intf0}  leaf1a-eth8
${bm2_intf1}  leaf1b-eth8
${bm3_intf0}  leaf1a-eth9
${bm3_intf1}  leaf1b-eth9
${bm4_intf0}  leaf2a-eth8
${bm4_intf1}  leaf2b-eth8
${bm5_intf0}  leaf2a-eth9
${bm5_intf1}  leaf2b-eth9

* Test Case 

Verify HA Cluster Formation
   [Tags]  ClusterFormation	 
   Verify the cluster formation 
   
Verify Cluster Election Take-Leader
	[Tags]  ClusterFormation
	Verify cluster election take leader
	
Verify Cluster Election Re-run
	[Tags]  ClusterFormation
	Verify cluster election rerun 
	
Verify Cluster Master Reboot
	[Tags]  ClusterFormation
	Reboot the master node & verify fabric integrity
	
Verify Cluster Slave Reboot
	[Tags]  ClusterFormation
	Reboot the Slave node & verify fabric integrity

Configure Cluster VIP & Verify Connectivity After Failover
	[Tags]   vip 
	rest add vip  10.192.106.20
	sleep  10
	${returnVal}=  cli verify cluster vip  10.192.106.20/32
	Should Be True  ${returnVal}

Delete Cluster VIP
	[Tags]   vip 
	rest delete vip
	sleep  10
	${returnVal}=  cli verify cluster vip  10.192.106.20/32
	Should Be False  ${returnVal}

Verify Cluster Master Shutdown
	[Tags]  ClusterFormation  skipped
	Shutdown the master node & verify fabric integrity
	
Verify Cluster Slave Shutdown
	[Tags]  ClusterFormation  skipped
	Shutdown the slave node & verify fabric integrity


##################################################
	#####	Traffic related test cases	##### 
##################################################

Master Failover/Failback & Verify Connectivity
   [Tags]  Traffic  
   Failover/Failback by rebooting the master and verify connectivity
   
Slave Failover/Failback & Verify Connectivity
   [Tags]  Traffic  
   Failover/Failback by rebooting the slave and verify connectivity

Cluster Election Take-Leader & Verify Connectivity
   [Tags]  Traffic  
   # To be: This test case only checks the take-leader in slave.
   # 			Need to implement this in the master
   Failover/Failback by issuing take-leader in master & verify connectivity

Cluster Election Re-run & Verify Connectivity
   [Tags]  Traffic  
   # To be: Make sure to do it on both master & slave when the commands
   #		are finalized
   Re-run the election and verify connectivity
   
Head-less Mode & Verify Connectivity
   [Tags]  Traffic  skipped
   Shutdown both the controllers and verify connectivity
   

* Keywords      

Verify the cluster formation 
	${returnVal}=  rest verify show cluster
	Should Be True  ${returnVal}

Verify cluster election take leader
	${returnVal}=  rest verify cluster election take leader
	Should Be True  ${returnVal}
	

Verify cluster election rerun 
	${returnVal}=  rest verify cluster election rerun
	Should Be True  ${returnVal}
	

Reboot the master node & verify fabric integrity
	${returnVal}=  cli verify cluster master reboot
	Should Be True  ${returnVal}
	
	
Reboot the Slave node & verify fabric integrity
	${returnVal}=  cli verify cluster slave reboot
	Should Be True  ${returnVal}
	
	
Shutdown the master node & verify fabric integrity
	${returnVal}=  cli verify cluster master shutdown
	Should Be True  ${returnVal}
	

Shutdown the slave node & verify fabric integrity
	${returnVal}=  cli verify cluster slave shutdown
	Should Be True  ${returnVal}
	
	
Failover/Failback by rebooting the master and verify connectivity
   : FOR    ${Iteration}    IN RANGE    1    3
   \	Log To Console   \n================ Rebooting Master - Iteration ${Iteration} ===============\n
   \	cli verify cluster master reboot
   \	platform ping all

Failover/Failback by rebooting the slave and verify connectivity
   : FOR    ${Iteration}    IN RANGE    1    3
   \	Log To Console   \n================ Rebooting Slave - Iteration ${Iteration} ===============\n
   \	cli verify cluster slave reboot
   \	platform ping all

Failover/Failback by issuing take-leader in master & verify connectivity
   : FOR    ${Iteration}    IN RANGE    1    3
   \	Log To Console   \n================ Election-Take-Leader - Iteration ${Iteration} ===============\n
   \	rest verify cluster election take leader
   \	platform ping all

Re-run the election and verify connectivity
   : FOR    ${Iteration}    IN RANGE    1    3
   \	Log To Console   \n================ Election-Rerun - Iteration ${Iteration} ===============\n
   \	rest verify cluster election rerun
   \	platform ping all

Shutdown both the controllers and verify connectivity
   platform ping all
   cli verify cluster slave shutdown
   cli verify cluster master shutdown
   platform ping all


Verify Single VNS Host Connectivity
   sleep  30
   add a tenant  bm_all
   add a vns  bm_all  bm_all
   add portgroup to vns  bm_all  bm_all  p1  -1
   add portgroup to vns  bm_all  bm_all  p2  -1
   add portgroup to vns  bm_all  bm_all  p3  -1
   add portgroup to vns  bm_all  bm_all  p4  -1
   add portgroup to vns  bm_all  bm_all  p5  -1
   add portgroup to vns  bm_all  bm_all  p6  -1
   sleep  30
   do show run vns verify  bm_all  6
   platform ping all

T5 base suite setup
   base suite setup
   ${spineList}=  Create List  00:00:00:00:00:01:00:01  00:00:00:00:00:01:00:02
   ${leafList}=  Create List  00:00:00:00:00:02:00:01  00:00:00:00:00:02:00:02  00:00:00:00:00:02:00:03  00:00:00:00:00:02:00:04  00:00:00:00:00:02:00:05  00:00:00:00:00:02:00:06
   auto configure fabric switch  ${spineList}  ${leafList}  2
   sleep  5
   add a portgroup  p1 
   add interface to portgroup  leaf0-a  ${bm0_intf0}  p1
   add interface to portgroup  leaf0-b  ${bm0_intf1}  p1
   add a portgroup  p2 
   add interface to portgroup  leaf0-a  ${bm1_intf0}  p2
   add interface to portgroup  leaf0-b  ${bm1_intf1}  p2
   add a portgroup  p3 
   add interface to portgroup  leaf1-a  ${bm2_intf0}  p3
   add interface to portgroup  leaf1-b  ${bm2_intf1}  p3
   add a portgroup  p4 
   add interface to portgroup  leaf1-a  ${bm3_intf0}  p4
   add interface to portgroup  leaf1-b  ${bm3_intf1}  p4
   add a portgroup  p5 
   add interface to portgroup  leaf2-a  ${bm4_intf0}  p5
   add interface to portgroup  leaf2-b  ${bm4_intf1}  p5
   add a portgroup  p6 
   add interface to portgroup  leaf2-a  ${bm5_intf0}  p6
   add interface to portgroup  leaf2-b  ${bm5_intf1}  p6
   sleep  5
   Verify Single VNS Host Connectivity

T5 base suite teardown   
   delete a tenant  bm_all
   delete interface from portgroup  leaf0-a  ${bm0_intf0}  p1
   delete interface from portgroup  leaf0-b  ${bm0_intf1}  p1
   delete a portgroup  p1
   delete interface from portgroup  leaf0-a  ${bm1_intf0}  p2
   delete interface from portgroup  leaf0-b  ${bm1_intf1}  p2
   delete a portgroup  p2
   delete interface from portgroup  leaf1-a  ${bm2_intf0}  p3
   delete interface from portgroup  leaf1-b  ${bm2_intf1}  p3
   delete a portgroup  p3
   delete interface from portgroup  leaf1-a  ${bm3_intf0}  p4
   delete interface from portgroup  leaf1-b  ${bm3_intf1}  p4
   delete a portgroup  p4
   delete interface from portgroup  leaf2-a  ${bm4_intf0}  p5
   delete interface from portgroup  leaf2-b  ${bm4_intf1}  p5
   delete a portgroup  p5
   delete interface from portgroup  leaf2-a  ${bm5_intf0}  p6
   delete interface from portgroup  leaf2-b  ${bm5_intf1}  p6
   delete a portgroup  p6
   auto delete fabric switch  $spineList  $leafList  2
   base suite teardown
   sleep  5

   
platform ping all
   platform ping  bm0  ${bm1_ip}
   platform ping  bm0  ${bm2_ip}
   platform ping  bm0  ${bm3_ip}
   platform ping  bm0  ${bm4_ip}
   platform ping  bm0  ${bm5_ip}
   platform ping  bm1  ${bm2_ip}
   platform ping  bm1  ${bm3_ip}
   platform ping  bm1  ${bm4_ip}
   platform ping  bm1  ${bm5_ip}
   platform ping  bm2  ${bm3_ip}
   platform ping  bm2  ${bm4_ip}
   platform ping  bm2  ${bm5_ip}
   platform ping  bm4  ${bm5_ip}


add a tenant  [Arguments]  ${tenant} 
  REST add tenant  ${tenant}    

delete a tenant  [Arguments]  ${tenant} 
  	REST delete tenant  ${tenant}    

add a vns  [Arguments]  ${tenant}  ${vns}  
	REST add vns  ${tenant}  ${vns}   

delete a vns  [Arguments]  ${tenant}  ${vns} 
  	REST delete vns  ${tenant}  ${vns}   

add a portgroup  [Arguments]  ${pg}
  	REST add portgroup  ${pg}    

delete a portgroup  [Arguments]  ${pg}
  	REST delete portgroup  ${pg}    

add a endpoint  [Arguments]  ${tenant}  ${vns}  ${endpoint} 
  	REST add endpoint  ${tenant}  ${vns}  ${endpoint}  

delete a endpoint  [Arguments]  ${tenant}  ${vns}  ${endpoint}
  	REST delete endpoint  ${tenant}  ${vns}  ${endpoint}  

add interface to portgroup  [Arguments]  ${switch}  ${intf}  ${pg} 
  	REST add interface to portgroup  ${switch}  ${intf}  ${pg}  

delete interface from portgroup  [Arguments]  ${switch}  ${intf}  ${pg} 
  	REST delete interface from portgroup  ${switch}  ${intf}  ${pg}  

add portgroup to vns  [Arguments]  ${tenant}  ${vns}  ${pg}  ${vlan}
  	REST add portgroup to vns  ${tenant}  ${vns}  ${pg}  ${vlan} 

add portgroup to endpoint  [Arguments]  ${tenant}  ${vns}  ${endpoint}  ${pg}  ${vlan} 
  REST add portgroup to endpoint  ${tenant}  ${vns}  ${endpoint}  ${pg}  ${vlan} 

delete portgroup from vns  [Arguments]  ${tenant}  ${vns}  ${pg}  ${vlan} 
  REST delete portgroup from vns  ${tenant}  ${vns}  ${pg}  ${vlan}
  

